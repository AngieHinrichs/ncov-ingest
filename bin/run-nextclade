#!/usr/bin/env bash

# HACK: Allows running nextclade on a large input fasta file:
#
#   - Splits fasta file into batches of a given size (Node.js is limited to max
#     GBytes file size)
#
#   - Runs batches one at a time. Nextclade uses a thread pool to schedule the
#     analysis of sequences in parallel, on per-sequence basis.
#
#   - Concatenates outputs from all batches
#
# TODO: This this script will be redundant when Nextclade implements a proper
#  streaming fasta reader, thus lifting the 2 GBytes limit. This will
#  effectively move batching inside Nextclade
#

set -o errexit
set -o nounset
set -o pipefail
trap "exit" INT

INPUT_FASTA=${1}
INPUT_TSV=${2}
OUTPUT_TSV=${3}
TMP_DIR_FASTA="tmp/fasta"
TMP_DIR_CLADES="tmp/clades"
INPUT_WILDCARD="${TMP_DIR_FASTA}/*.fasta"
OUTPUT_WILDCARD="${TMP_DIR_CLADES}/*.tsv"

BATCH_SIZE=200

# Default number of processes, if not provided.
# Usually equals to the sum of numbers of logical cores ("threads") on all CPUs
# in the system combined, including "hyperthreads".
N_PROCESSES_DEFAULT=$(getconf _NPROCESSORS_ONLN)

# Alternatively, use number of processes provided as the third argument
N_PROCESSES=${4:-"${N_PROCESSES_DEFAULT}"}

# Split fasta file to multiple batches
mkdir -p "${TMP_DIR_FASTA}"
./bin/split-fasta \
  "${INPUT_FASTA}" \
  --batch_size=${BATCH_SIZE} \
  --output_dir="${TMP_DIR_FASTA}"

# Run batches in parallel
echo "Using ${N_PROCESSES} parallel processes"
mkdir -p "${TMP_DIR_CLADES}"
for input in ${INPUT_WILDCARD}; do
  input_basename="$(basename "${input}")"
  output_basename="${input_basename%.fasta}.tsv"
  output_filename="${TMP_DIR_CLADES}/${output_basename}"

  echo "Processing ${input}"
  nextclade.js \
    --jobs="${N_PROCESSES}" \
    --input-fasta="${input}" \
    --output-tsv="${output_filename}"
done

cp "${INPUT_TSV}" "${OUTPUT_TSV}"

# Concatenate output batches together
for output in ${OUTPUT_WILDCARD}; do
  ./bin/join-rows $output "${OUTPUT_TSV}" -o "${OUTPUT_TSV}"
done

#rm -rf "${TMP_DIR_FASTA}" "${TMP_DIR_CLADES}"
